---
title: "Causal ML Homework 2 - code (part I)"
author: "Luis Armona and Jack Blundell"
date: "May 22, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup

```{r load, echo=F, message=FALSE, warning=FALSE}
# set your working directory

#setwd("C:/Users/Jack/Documents/Git/AtheyMLhw2") # Jack
setwd('/home/luis/AtheyMLhw2') #Luis
# clear things in RStudio

rm(list = ls())


# Call packages

library(ggplot2)
#library(dplyr)
#library(reshape2)
#library(glmnet)
#library(plotmo)
#library(pogs)
#library(balanceHD)
library(causalTree)
library(randomForestCI)
library(reshape2)
library(plyr)
library(gradient.forest)



fname <- 'Data/charitable_withdummyvariables.csv'
char <- read.csv(fname)

```

First drop observations as in HW1 to make this into an observational study

```{r drop, echo=TRUE}

#randomly censor individuals
# via a  complex, highly nonlinear fcn 
#

ps.fcn <- function(v,c,pg,t){
  #v_t <- (v-.25)/.5
  v_t <- v
  #ihs_pg <- log(pg + sqrt(pg ^ 2 + 1))/5
  #p<- (c*(acos(v_t))*atan(v_t^2)  - .5*exp(v_t))/4 + (t*((ihs_pg)) + (1-t))/2
  ihs_pg <- log(pg + sqrt(pg ^ 2 + 1))
  p<- (1-t)*(c+1)*(acos(v_t)*atan(v_t) )/3 + 
      t*(.01+(-.01*ihs_pg^5 + 1*ihs_pg^3)/300)
  p<- pmin(pmax(0,p),1)
  return(p)
}
#story to accompany this fcn: ACLU wants to help those in trouble in "red states" but do not 
#feel they can make a difference in really, really red states so target donors less often


# Selection rule
char$ps.select <- ps.fcn(char$perbush,char$cases,char$hpa,char$treatment) # hpa is highest previous contribution. cases is court cases from state which organization was involved.
#deal with those missing covariates
char$ps.select[ which(char$perbush==-999
            | char$cases==-999
            | char$hpa==-999)] <- 0.5

# Set seed
set.seed(21) 

#replace -999s with 0s (since there are already missing dummies)
for (v in names(char)){
  mi_v <- paste(v,'_missing',sep='') 
  if (mi_v %in% names(char)){
    print(paste('fixing',v))
    char[(char[,mi_v]==1),v]<-0
  }
}

# Selection rule (=1 of uniform random [0,1] is lower, so those with higher ps.true more likely to be selected)
selection <- runif(nrow(char)) <= char$ps.select
prop.treat <-  mean(char$treatment)
char$ps.select.t <- ps.fcn(char$perbush,char$cases,char$hpa,1)
char$ps.select.c <- ps.fcn(char$perbush,char$cases,char$hpa,0)
char$ps.true <- (prop.treat*char$ps.select.t)/(prop.treat*char$ps.select.t + (1 - prop.treat)*char$ps.select.c)

char.censored <- char[selection,] #remove observations via propensity score rule


```

Further setup our data ready to feed into functions.

```{r obs setup.obs, echo=T}

# Extract the dependent variable
Y <- char.censored[["out_amountgive"]]

# Extract treatment
W <- char.censored[["treatment"]]

# Extract covariates from main DF
covariates <- char.censored[,c(14:22,23:63)] # inc missing dummies for now
covariate.names <- names(covariates)

# standardize features to have mean 0 and std 1
covariates.scaled <- scale(covariates)
processed.unscaled <- data.frame(Y, W, covariates)
processed.scaled <- data.frame(Y, W, covariates.scaled)

# partition data into training and test sets.
set.seed(44)
sample.main <- sample(nrow(processed.scaled), round(9*nrow(processed.scaled)/10), replace=FALSE)

processed.scaled.train <- processed.scaled[sample.main,]
processed.scaled.test <- processed.scaled[-sample.main,]

y.train <- as.matrix(processed.scaled.train$Y, ncol=1)
y.test <- as.matrix(processed.scaled.test$Y, ncol=1)

# create RHS of R formulas both with linear and second order interaction
print(covariate.names)
sumx = paste(covariate.names, collapse = " + ")  # "X1 + X2 + X3 + ..." for substitution later
interx = paste(" (",sumx, ")^2", sep="")  # "(X1 + X2 + X3 + ...)^2" for substitution later

```

Next set some parameters for causal tree / forest

```{r obs setup.params, echo=T}
# Create additional datasets
#LA: Jack what is this for?
processed.scaled.testW0 <- processed.scaled.test
processed.scaled.testW0$W <- rep(0,nrow(processed.scaled.test))

processed.scaled.testW1 <- processed.scaled.test
processed.scaled.testW1$W <- rep(1,nrow(processed.scaled.test))

# causal tree/forest params

# Set parameters

#go with honest Causal Tree Splitting/Cross Validation
#with original weighting between MSE and variance term
#and bucket splitting in the training process (w/ 5 buckets as a target)
# and a minimum of 100 (50T + 50C) in each leaf
split.Rule.temp = "CT"
cv.option.temp = "CT"
split.Honest.temp = T
cv.Honest.temp = T
split.alpha.temp = .5
cv.alpha.temp = .5
split.Bucket.temp = T
bucketMax.temp= 100
bucketNum.temp = 5
minsize.temp=50


# number of trees (try 1000 once all working)
numtreesCT <- 1000
numtreesGF <- 1000

```

Now lets try propensity forest. Remember no honest estimation here.

```{r obs propens.forest, echo=F}


# Propensity forest

#total number of covariates in our dataset
ncolx <- ncol(processed.scaled.train)-2 
ncov_sample<-floor(ncolx/3) #number of covariates (randomly sampled) to use to build tree

#estimate the PF using no bucket splits and 50 obs total in each 
#with 1/2 of the data resampled for each tree to estimate the tree,
#1/2 used to CV
#don't do honest splitting for evaluation of CT risk function.
#but do use the CT risk criterion
set.seed(92)
pf <- propensityForest(as.formula(paste("Y~",sumx)), 
                       data=processed.scaled.train,
                       treatment=processed.scaled.train$W, 
                       split.Rule = "CT",
                       split.Honest = F,
                       cv.option = "CT",
                       cv.Honest = F,
                       split.Bucket=F, 
                       sample.size.total==floor(nrow(processed.scaled.train) / 2), 
                       sample.size.train.frac=1, 
                       nodesize = 25, num.trees=numtreesCT, ncolx=ncolx, ncov_sample=ncov_sample )

#given our p-forest, predict average CATE for each test datapoint from each estimated tree
#by averaging over all the trees
pfpredtest <- predict(pf, newdata=processed.scaled.test, type="vector")

#the predicted CATEs for the original test dataset
pfpredtrainall <- predict(pf, newdata=processed.scaled.train, 
                          predict.all = TRUE, type="vector")
print(c("mean of ATE treatment effect from propensityForest on Training data", 
        round(mean(pfpredtrainall$aggregate),5)))
print(c("mean of ATE treatment effect from propensityForest on Test data",
         round(mean(pfpredtest),5)))
#calculate the variance of the individual estimates of the treatment effects for each individual
#in the training data
pfvar.train <- infJack(pfpredtrainall$individual, pf$inbag, calibrate = TRUE)
plot(pfvar.train)


#plot "true" propensity score versus CATE from propensity forest
#using test dataset
ggplot(char.censored[-sample.main,],aes(y=pfpredtest,x=ps.true)) + geom_point(alpha=.5) +
  geom_smooth(fill=NA,method='loess') + 
  ylab('CATE') + xlab('Propensity Score')
ggsave('./plots/PFCATEvPS.pdf')
```

# Now lets try gradient forest, first without residualizing

```{r obs gradient.forest, echo=T}

X = as.matrix(processed.scaled.train[,covariate.names])
X.test = as.matrix(processed.scaled.test[,covariate.names])
Y  = as.matrix(processed.scaled.train[,"Y"])
W  = as.matrix(processed.scaled.train[,"W"])

#do gradient forest estimation of causal forest w/ honest splitting
set.seed(93)
gf <- causal.forest(X, Y, W,sample.fraction=.5,
                    num.trees = numtreesGF, ci.group.size = 4,
                    honesty=T,min.node.size = 50,
                    mtry=ncov_sample,
                    precompute.nuisance = FALSE,seed=93)
#predict training-out-of-bag CATEs, then test CATEs from causal forest in GF pkg.
preds.causal.oob = predict(gf, estimate.variance=TRUE)
preds.causal.test = predict(gf, X.test, estimate.variance=TRUE)

# training set
mean(preds.causal.oob$predictions)  
plot(preds.causal.oob$predictions, preds.causal.oob$variance.estimates)

# test set (honest)
mean(preds.causal.test$predictions)  
plot(preds.causal.test$predictions, preds.causal.test$variance.estimates)

#we get very similar estimations.

```

# Next the same but residualizing

```{r obs gradient.forest.res, echo=T}

# estimate conditional means of Y|X using regression forests, then subtract to obtain residuals
#don't need CI so don't build multiple trees on each subsample.
seed(99)
Yrf <- regression.forest(X, Y, num.trees = numtreesGF,min.node.size=50, 
                         sample.fraction=.5,honesty=T,mtry=ncov_sample,
                         ci.group.size = 1)
Yresid <- Y - predict(Yrf)$prediction

# same as above but for the treatment indicator
Wrf <- regression.forest(X, W, num.trees = numtreesGF,min.node.size=50, 
                         sample.fraction=.5,honesty=T,mtry=ncov_sample,
                         ci.group.size = 1)
Wresid <- W - predict(Wrf)$predictions

#do the same thing as before but now on the residuals
gf.resids <- causal.forest(X,Yresid,Wresid,sample.fraction=.5,
                    num.trees = numtreesGF, ci.group.size = 4,
                    honesty=T,min.node.size = 50,
                    mtry=ncov_sample,
                    precompute.nuisance = FALSE,seed=93)

#the following code does the same residualization but within the causal.forest call
gf.resids.within <- causal.forest(X,Y,W,sample.fraction=.5,
                    num.trees = numtreesGF, ci.group.size = 4,
                    honesty=T,min.node.size = 50,
                    mtry=ncov_sample,
                    precompute.nuisance = TRUE,seed=93)


#validate by comparing the two outputs

# training set out of bag estimates
preds.causalr.oob = predict(gf.resids, estimate.variance=TRUE)
mean(preds.causalr.oob$predictions)  
plot(preds.causalr.oob$predictions, preds.causalr.oob$variance.estimates)



# test set (honest)
Xtest = as.matrix(processed.scaled.test[,covariate.names])
preds.causalr.test = predict(gf.resids, Xtest, estimate.variance=TRUE)
preds.causalr.test.within = predict(gf.resids.within, Xtest, estimate.variance=TRUE)
mean(preds.causalr.test$predictions)  
mean(preds.causalr.test.within$predictions)  

plot(preds.causalr.test$predictions, preds.causalr.test$variance.estimates)

plot(preds.causalr.test$predictions,preds.causalr.test.within$predictions)

#mean much closer to truth in the residualized GF routine

#compare variances w/ and w/o residuals
print('Average Variance of CATEs by residualization')
print('raw scaled data:')
mean(preds.causal.test$variance.estimates) 
print('with residuals: ')
mean(preds.causalr.test.within$variance.estimates) 

#residualizing increases variance due to random component of the conditional mean estimation?

```
